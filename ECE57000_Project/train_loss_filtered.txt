Iteration 0, training loss = 6.536, validation loss = 6.012, ber = 0.04761
Iteration 100, training loss = 0.491, validation loss = 0.448, ber = 0.01931
Iteration 200, training loss = 0.402, validation loss = 0.408, ber = 0.01926
Iteration 300, training loss = 0.405, validation loss = 0.423, ber = 0.02025
Iteration 400, training loss = 0.445, validation loss = 0.412, ber = 0.01988
Iteration 500, training loss = 0.399, validation loss = 0.408, ber = 0.01959
Iteration 600, training loss = 0.420, validation loss = 0.413, ber = 0.01973
Iteration 700, training loss = 0.355, validation loss = 0.411, ber = 0.01976
Iteration 800, training loss = 0.446, validation loss = 0.411, ber = 0.02008
Iteration 900, training loss = 0.420, validation loss = 0.406, ber = 0.01938
Iteration 1000, training loss = 0.435, validation loss = 0.400, ber = 0.01927
Iteration 1100, training loss = 0.444, validation loss = 0.402, ber = 0.01931
Iteration 1200, training loss = 0.438, validation loss = 0.417, ber = 0.02022
Iteration 1300, training loss = 0.401, validation loss = 0.398, ber = 0.01889
Iteration 1400, training loss = 0.402, validation loss = 0.410, ber = 0.01993
Iteration 1500, training loss = 0.432, validation loss = 0.402, ber = 0.01910
Iteration 1600, training loss = 0.441, validation loss = 0.409, ber = 0.01994
Iteration 1700, training loss = 0.430, validation loss = 0.402, ber = 0.01932
Iteration 1800, training loss = 0.352, validation loss = 0.402, ber = 0.01945
Iteration 1900, training loss = 0.402, validation loss = 0.411, ber = 0.01977
Iteration 2000, training loss = 0.414, validation loss = 0.407, ber = 0.01947
Iteration 2100, training loss = 0.426, validation loss = 0.410, ber = 0.01969
Iteration 2200, training loss = 0.428, validation loss = 0.405, ber = 0.01958
Iteration 2300, training loss = 0.453, validation loss = 0.402, ber = 0.01941
Iteration 2400, training loss = 0.427, validation loss = 0.401, ber = 0.01925
Iteration 2500, training loss = 0.444, validation loss = 0.408, ber = 0.01960
Iteration 2600, training loss = 0.397, validation loss = 0.407, ber = 0.01982
Iteration 2700, training loss = 0.432, validation loss = 0.405, ber = 0.01945
Iteration 2800, training loss = 0.442, validation loss = 0.416, ber = 0.02004
Iteration 2900, training loss = 0.392, validation loss = 0.407, ber = 0.01947
Iteration 3000, training loss = 0.454, validation loss = 0.401, ber = 0.01933
Iteration 3100, training loss = 0.415, validation loss = 0.407, ber = 0.01942
Iteration 3200, training loss = 0.394, validation loss = 0.414, ber = 0.01990
Iteration 3300, training loss = 0.412, validation loss = 0.400, ber = 0.01915
Iteration 3400, training loss = 0.380, validation loss = 0.413, ber = 0.01985
Iteration 0, training loss = 0.410, validation loss = 0.402, ber = 0.01935
Iteration 100, training loss = 0.399, validation loss = 0.416, ber = 0.01990
Iteration 200, training loss = 0.393, validation loss = 0.399, ber = 0.01921
Iteration 300, training loss = 0.376, validation loss = 0.405, ber = 0.01954
Iteration 400, training loss = 0.411, validation loss = 0.399, ber = 0.01921
Iteration 500, training loss = 0.390, validation loss = 0.403, ber = 0.01931
Iteration 600, training loss = 0.442, validation loss = 0.409, ber = 0.01976
Iteration 700, training loss = 0.374, validation loss = 0.403, ber = 0.01925
Iteration 800, training loss = 0.462, validation loss = 0.414, ber = 0.01996
Iteration 900, training loss = 0.436, validation loss = 0.413, ber = 0.01975
Iteration 1000, training loss = 0.402, validation loss = 0.406, ber = 0.01948
Iteration 1100, training loss = 0.411, validation loss = 0.400, ber = 0.01931
Iteration 1200, training loss = 0.413, validation loss = 0.403, ber = 0.01937
Iteration 1300, training loss = 0.409, validation loss = 0.402, ber = 0.01922
Iteration 1400, training loss = 0.385, validation loss = 0.403, ber = 0.01931
Iteration 1500, training loss = 0.451, validation loss = 0.411, ber = 0.01997
Iteration 1600, training loss = 0.437, validation loss = 0.403, ber = 0.01939
Iteration 1700, training loss = 0.415, validation loss = 0.406, ber = 0.01949
Iteration 1800, training loss = 0.377, validation loss = 0.408, ber = 0.01950
Iteration 1900, training loss = 0.423, validation loss = 0.404, ber = 0.01945
Iteration 2000, training loss = 0.431, validation loss = 0.409, ber = 0.01982
Iteration 2100, training loss = 0.437, validation loss = 0.409, ber = 0.01954
Iteration 2200, training loss = 0.414, validation loss = 0.402, ber = 0.01937
Iteration 2300, training loss = 0.439, validation loss = 0.401, ber = 0.01946
Iteration 2400, training loss = 0.431, validation loss = 0.407, ber = 0.01940
Iteration 2500, training loss = 0.399, validation loss = 0.405, ber = 0.01927
Iteration 2600, training loss = 0.409, validation loss = 0.410, ber = 0.01973
Iteration 2700, training loss = 0.426, validation loss = 0.407, ber = 0.01964
Iteration 2800, training loss = 0.433, validation loss = 0.406, ber = 0.01955
Iteration 2900, training loss = 0.372, validation loss = 0.408, ber = 0.01968
Iteration 3000, training loss = 0.461, validation loss = 0.405, ber = 0.01950
Iteration 3100, training loss = 0.440, validation loss = 0.403, ber = 0.01917
Iteration 3200, training loss = 0.453, validation loss = 0.413, ber = 0.01987
Iteration 3300, training loss = 0.429, validation loss = 0.411, ber = 0.01996
Iteration 3400, training loss = 0.351, validation loss = 0.411, ber = 0.01979
Iteration 3500, training loss = 0.370, validation loss = 0.410, ber = 0.01975
Iteration 3600, training loss = 0.374, validation loss = 0.407, ber = 0.01972
Iteration 3700, training loss = 0.417, validation loss = 0.409, ber = 0.01976
Iteration 3800, training loss = 0.389, validation loss = 0.414, ber = 0.01986
Iteration 3900, training loss = 0.433, validation loss = 0.409, ber = 0.01968
Iteration 4000, training loss = 0.415, validation loss = 0.401, ber = 0.01925
Iteration 4100, training loss = 0.458, validation loss = 0.404, ber = 0.01952
Iteration 4200, training loss = 0.451, validation loss = 0.405, ber = 0.01957
Iteration 4300, training loss = 0.403, validation loss = 0.398, ber = 0.01920
Iteration 4400, training loss = 0.395, validation loss = 0.410, ber = 0.01980
Iteration 4500, training loss = 0.395, validation loss = 0.404, ber = 0.01942
Iteration 4600, training loss = 0.429, validation loss = 0.406, ber = 0.01949
Iteration 4700, training loss = 0.413, validation loss = 0.414, ber = 0.02007
Iteration 4800, training loss = 0.376, validation loss = 0.410, ber = 0.01957
Iteration 4900, training loss = 0.408, validation loss = 0.410, ber = 0.01973
Iteration 5000, training loss = 0.440, validation loss = 0.412, ber = 0.01996
Iteration 5100, training loss = 0.440, validation loss = 0.410, ber = 0.01980
Iteration 5200, training loss = 0.382, validation loss = 0.406, ber = 0.01943
Iteration 5300, training loss = 0.488, validation loss = 0.403, ber = 0.01941
Iteration 5400, training loss = 0.449, validation loss = 0.402, ber = 0.01945
Iteration 5500, training loss = 0.432, validation loss = 0.402, ber = 0.01928
Iteration 5600, training loss = 0.431, validation loss = 0.400, ber = 0.01921
Iteration 5700, training loss = 0.403, validation loss = 0.405, ber = 0.01941
Iteration 5800, training loss = 0.407, validation loss = 0.400, ber = 0.01947
Iteration 5900, training loss = 0.446, validation loss = 0.400, ber = 0.01918
Iteration 6000, training loss = 0.336, validation loss = 0.407, ber = 0.01960
Iteration 6100, training loss = 0.431, validation loss = 0.406, ber = 0.01940
Iteration 6200, training loss = 0.434, validation loss = 0.403, ber = 0.01960
Iteration 6300, training loss = 0.407, validation loss = 0.411, ber = 0.01965
Iteration 6400, training loss = 0.406, validation loss = 0.406, ber = 0.01953
Iteration 6500, training loss = 0.347, validation loss = 0.400, ber = 0.01936
Iteration 6600, training loss = 0.405, validation loss = 0.408, ber = 0.01948
Iteration 6700, training loss = 0.455, validation loss = 0.401, ber = 0.01913
Iteration 6800, training loss = 0.411, validation loss = 0.406, ber = 0.01941
Iteration 6900, training loss = 0.371, validation loss = 0.405, ber = 0.01961
Iteration 7000, training loss = 0.369, validation loss = 0.415, ber = 0.02000
Iteration 7100, training loss = 0.422, validation loss = 0.415, ber = 0.02001
Iteration 7200, training loss = 0.405, validation loss = 0.403, ber = 0.01939
Iteration 7300, training loss = 0.396, validation loss = 0.403, ber = 0.01918
Iteration 7400, training loss = 0.436, validation loss = 0.410, ber = 0.01985
Iteration 7500, training loss = 0.435, validation loss = 0.401, ber = 0.01925
Iteration 7600, training loss = 0.411, validation loss = 0.408, ber = 0.01977
Iteration 7700, training loss = 0.389, validation loss = 0.405, ber = 0.01942
Iteration 7800, training loss = 0.415, validation loss = 0.406, ber = 0.01937
Iteration 7900, training loss = 0.447, validation loss = 0.416, ber = 0.01997
Iteration 8000, training loss = 0.385, validation loss = 0.405, ber = 0.01934
Iteration 8100, training loss = 0.385, validation loss = 0.406, ber = 0.01940
Iteration 8200, training loss = 0.459, validation loss = 0.411, ber = 0.01973
Iteration 8300, training loss = 0.361, validation loss = 0.406, ber = 0.01956
Iteration 8400, training loss = 0.439, validation loss = 0.404, ber = 0.01929
Iteration 8500, training loss = 0.397, validation loss = 0.414, ber = 0.01997
Iteration 8600, training loss = 0.384, validation loss = 0.405, ber = 0.01946
Iteration 8700, training loss = 0.416, validation loss = 0.410, ber = 0.01987
Iteration 8800, training loss = 0.367, validation loss = 0.407, ber = 0.01969
Iteration 8900, training loss = 0.372, validation loss = 0.400, ber = 0.01922
Iteration 9000, training loss = 0.391, validation loss = 0.409, ber = 0.01945
Iteration 9100, training loss = 0.410, validation loss = 0.409, ber = 0.01977
Iteration 9200, training loss = 0.365, validation loss = 0.408, ber = 0.01961
Iteration 9300, training loss = 0.420, validation loss = 0.408, ber = 0.01953
Iteration 9400, training loss = 0.399, validation loss = 0.405, ber = 0.01946
Iteration 9500, training loss = 0.397, validation loss = 0.409, ber = 0.01975
Iteration 9600, training loss = 0.387, validation loss = 0.407, ber = 0.01954
Iteration 9700, training loss = 0.452, validation loss = 0.410, ber = 0.01977
Iteration 9800, training loss = 0.398, validation loss = 0.412, ber = 0.01978
Iteration 9900, training loss = 0.378, validation loss = 0.409, ber = 0.01961
Iteration 0, training loss = 0.386, validation loss = 0.409, ber = 0.01965
Iteration 100, training loss = 0.394, validation loss = 0.409, ber = 0.01963
Iteration 200, training loss = 0.364, validation loss = 0.409, ber = 0.01974
Iteration 300, training loss = 0.405, validation loss = 0.414, ber = 0.01978
Iteration 400, training loss = 0.403, validation loss = 0.409, ber = 0.01961
Iteration 500, training loss = 0.347, validation loss = 0.402, ber = 0.01922
Iteration 600, training loss = 0.403, validation loss = 0.410, ber = 0.01962
Iteration 700, training loss = 0.338, validation loss = 0.404, ber = 0.01951
Iteration 800, training loss = 0.448, validation loss = 0.404, ber = 0.01935
Iteration 900, training loss = 0.450, validation loss = 0.405, ber = 0.01948
Iteration 1000, training loss = 0.402, validation loss = 0.404, ber = 0.01938
Iteration 1100, training loss = 0.437, validation loss = 0.404, ber = 0.01935
Iteration 1200, training loss = 0.388, validation loss = 0.406, ber = 0.01977
Iteration 1300, training loss = 0.398, validation loss = 0.406, ber = 0.01959
Iteration 1400, training loss = 0.440, validation loss = 0.403, ber = 0.01941
Iteration 1500, training loss = 0.446, validation loss = 0.407, ber = 0.01950
Iteration 1600, training loss = 0.437, validation loss = 0.404, ber = 0.01950
Iteration 1700, training loss = 0.406, validation loss = 0.415, ber = 0.01996
Iteration 1800, training loss = 0.385, validation loss = 0.411, ber = 0.01990
Iteration 1900, training loss = 0.422, validation loss = 0.412, ber = 0.01976
Iteration 2000, training loss = 0.455, validation loss = 0.403, ber = 0.01939
Iteration 2100, training loss = 0.440, validation loss = 0.415, ber = 0.01993
Iteration 2200, training loss = 0.413, validation loss = 0.407, ber = 0.01971
Iteration 2300, training loss = 0.424, validation loss = 0.407, ber = 0.01957
Iteration 2400, training loss = 0.421, validation loss = 0.401, ber = 0.01944
Iteration 2500, training loss = 0.404, validation loss = 0.402, ber = 0.01946
Iteration 2600, training loss = 0.404, validation loss = 0.405, ber = 0.01950
Iteration 2700, training loss = 0.437, validation loss = 0.409, ber = 0.01969
Iteration 2800, training loss = 0.407, validation loss = 0.404, ber = 0.01938
Iteration 2900, training loss = 0.361, validation loss = 0.409, ber = 0.01978
Iteration 3000, training loss = 0.421, validation loss = 0.403, ber = 0.01939
Iteration 3100, training loss = 0.426, validation loss = 0.398, ber = 0.01933
Iteration 3200, training loss = 0.388, validation loss = 0.408, ber = 0.01970
Iteration 3300, training loss = 0.411, validation loss = 0.406, ber = 0.01973
Iteration 3400, training loss = 0.339, validation loss = 0.401, ber = 0.01940
Iteration 3500, training loss = 0.414, validation loss = 0.406, ber = 0.01948
Iteration 3600, training loss = 0.396, validation loss = 0.401, ber = 0.01911
Iteration 3700, training loss = 0.384, validation loss = 0.415, ber = 0.02004
Iteration 3800, training loss = 0.376, validation loss = 0.408, ber = 0.01971
Iteration 3900, training loss = 0.440, validation loss = 0.414, ber = 0.01992
Iteration 4000, training loss = 0.391, validation loss = 0.418, ber = 0.01994
Iteration 4100, training loss = 0.430, validation loss = 0.412, ber = 0.01990
Iteration 4200, training loss = 0.410, validation loss = 0.400, ber = 0.01944
Iteration 4300, training loss = 0.415, validation loss = 0.403, ber = 0.01962
Iteration 4400, training loss = 0.385, validation loss = 0.409, ber = 0.01971
Iteration 4500, training loss = 0.378, validation loss = 0.401, ber = 0.01927
Iteration 4600, training loss = 0.434, validation loss = 0.414, ber = 0.01987
Iteration 4700, training loss = 0.424, validation loss = 0.399, ber = 0.01928
Iteration 4800, training loss = 0.369, validation loss = 0.409, ber = 0.01959
Iteration 4900, training loss = 0.389, validation loss = 0.407, ber = 0.01951
Iteration 5000, training loss = 0.410, validation loss = 0.411, ber = 0.01978
Iteration 5100, training loss = 0.423, validation loss = 0.404, ber = 0.01932
Iteration 5200, training loss = 0.387, validation loss = 0.403, ber = 0.01961
Iteration 5300, training loss = 0.450, validation loss = 0.399, ber = 0.01915
Iteration 5400, training loss = 0.437, validation loss = 0.409, ber = 0.01993
Iteration 5500, training loss = 0.407, validation loss = 0.397, ber = 0.01898
Iteration 5600, training loss = 0.401, validation loss = 0.408, ber = 0.01962
Iteration 5700, training loss = 0.409, validation loss = 0.420, ber = 0.02016
Iteration 5800, training loss = 0.431, validation loss = 0.403, ber = 0.01951
Iteration 5900, training loss = 0.422, validation loss = 0.405, ber = 0.01955
Iteration 6000, training loss = 0.332, validation loss = 0.405, ber = 0.01943
Iteration 6100, training loss = 0.438, validation loss = 0.411, ber = 0.01985
Iteration 6200, training loss = 0.453, validation loss = 0.408, ber = 0.01957
Iteration 6300, training loss = 0.437, validation loss = 0.410, ber = 0.01969
Iteration 6400, training loss = 0.443, validation loss = 0.408, ber = 0.01973
Iteration 6500, training loss = 0.396, validation loss = 0.405, ber = 0.01960
Iteration 6600, training loss = 0.378, validation loss = 0.408, ber = 0.01946
Iteration 6700, training loss = 0.454, validation loss = 0.409, ber = 0.01968
Iteration 6800, training loss = 0.401, validation loss = 0.409, ber = 0.01972
Iteration 6900, training loss = 0.404, validation loss = 0.406, ber = 0.01962
Iteration 7000, training loss = 0.360, validation loss = 0.403, ber = 0.01936
Iteration 7100, training loss = 0.450, validation loss = 0.414, ber = 0.01984
Iteration 7200, training loss = 0.383, validation loss = 0.409, ber = 0.01980
Iteration 7300, training loss = 0.378, validation loss = 0.406, ber = 0.01953
Iteration 7400, training loss = 0.416, validation loss = 0.400, ber = 0.01919
Iteration 7500, training loss = 0.425, validation loss = 0.404, ber = 0.01933
Iteration 7600, training loss = 0.427, validation loss = 0.408, ber = 0.01944
Iteration 7700, training loss = 0.383, validation loss = 0.405, ber = 0.01947
Iteration 7800, training loss = 0.401, validation loss = 0.406, ber = 0.01961
Iteration 7900, training loss = 0.431, validation loss = 0.408, ber = 0.01966
Iteration 8000, training loss = 0.400, validation loss = 0.407, ber = 0.01943
Iteration 8100, training loss = 0.373, validation loss = 0.403, ber = 0.01929
Iteration 8200, training loss = 0.428, validation loss = 0.413, ber = 0.01992
Iteration 8300, training loss = 0.388, validation loss = 0.400, ber = 0.01910
Iteration 8400, training loss = 0.444, validation loss = 0.407, ber = 0.01964
Iteration 8500, training loss = 0.416, validation loss = 0.403, ber = 0.01926
Iteration 8600, training loss = 0.436, validation loss = 0.408, ber = 0.01958
Iteration 8700, training loss = 0.410, validation loss = 0.405, ber = 0.01957
Iteration 8800, training loss = 0.394, validation loss = 0.409, ber = 0.01983
Iteration 8900, training loss = 0.388, validation loss = 0.399, ber = 0.01939
Iteration 9000, training loss = 0.431, validation loss = 0.406, ber = 0.01966
Iteration 9100, training loss = 0.430, validation loss = 0.401, ber = 0.01919
Iteration 9200, training loss = 0.367, validation loss = 0.404, ber = 0.01945
Iteration 9300, training loss = 0.405, validation loss = 0.410, ber = 0.01969
Iteration 9400, training loss = 0.427, validation loss = 0.411, ber = 0.01995
Iteration 9500, training loss = 0.393, validation loss = 0.411, ber = 0.01970
Iteration 9600, training loss = 0.392, validation loss = 0.410, ber = 0.01972
Iteration 9700, training loss = 0.452, validation loss = 0.408, ber = 0.01977
Iteration 9800, training loss = 0.346, validation loss = 0.400, ber = 0.01928
Iteration 9900, training loss = 0.366, validation loss = 0.408, ber = 0.01972
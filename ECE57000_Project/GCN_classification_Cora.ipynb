{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP0j6j75bF+S79Aen0HGeEI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Using the Cora dataset, a common benchmark dataset for graph learning tasks, where each node is a document, edges represent citations, and node features represent word occurrences, a GCN model for classification is constructed."],"metadata":{"id":"GN-OnT8Qw_lC"}},{"cell_type":"markdown","source":["Problem Statement:\n","\n","This Classification task is a form of node classification within a graph structure. Each node represents a scientific document, and the objective is to correctly classify each document into one of several predefined categories based on the content of the document and its citation network.\n","\n","1. Dataset Characteristics:\n","*   Nodes: Each node in the Cora dataset represents a scientific publication.\n","*   Node Features: Each node has a feature vector derived from the textual content of the document. Specifically, the features are binary word vectors indicating the presence or absence of corresponding words from a predefined dictionary.\n","*   Edges: Each edge represents a citation link between two documents, meaning that one document cites another. This creates a directed graph where the direction points from the citing document to the cited document.\n","\n","2. Classes:\n","*   The Cora dataset typically includes seven different classes that correspond to different areas of machine learning and computer science, such as Genetic Algorithms, Neural Networks, Probabilistic Methods, etc. Each class represents a field of study that the document could belong to.\n","\n","3. The goal is to predict the class (field of study) for each document based on its content and its position within the citation network. This is a classic semi-supervised learning problem where only a subset of the nodes (documents) have labeled data. The GCN leverages both the node features and the graph structure to learn how to classify nodes.\n","\n","4. Why Graph Neural Networks:\n","*   Graph Neural Networks (specifically GCN in this case) are particularly suited for this type of problem because they can efficiently propagate label information through the graph structure. By learning from both the local (node features) and global (graph structure) information, GCNs can predict labels for unlabeled nodes effectively.\n","*   GCNs use the node features and the edges (citations) to aggregate information from a node’s neighborhood (including itself), which helps in capturing both the topical relevance and the contextual relevance (how nodes influence each other through citations).\n","\n","For example, if a particular document is about \"Neural Networks\" and it cites other documents about \"Neural Networks,\" and is cited by documents about \"Neural Networks,\" a GCN can help to identify that the document likely belongs to the category of \"Neural Networks\" even if the document's label is unknown. This capability makes GCNs highly effective for tasks where the relational structure between data points significantly informs or affects the output variable."],"metadata":{"id":"F_j_3IfTC3tT"}},{"cell_type":"code","source":["!pip install torch-geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EnVu0XWZxOUp","executionInfo":{"status":"ok","timestamp":1730769162372,"user_tz":300,"elapsed":6495,"user":{"displayName":"Manish_Kumar Deep_Learning","userId":"10787978629583361420"}},"outputId":"ad4e8e52-1531-4aef-a426-446ff76499c5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch-geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.17.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.6.1\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8fsFKI9hwrAp","executionInfo":{"status":"ok","timestamp":1730769176422,"user_tz":300,"elapsed":14052,"user":{"displayName":"Manish_Kumar Deep_Learning","userId":"10787978629583361420"}}},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.data import DataLoader\n","from torch_geometric.utils import to_networkx\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","source":["# Load the Cora dataset (each node represents a document, each edge represents a citation)\n","dataset = Planetoid(root=\"data/Cora\", name=\"Cora\")\n","\n","# Get the first graph from the dataset (Cora has only one graph)\n","data = dataset[0]\n","print(f\"Dataset has {len(dataset)} graph(s). Each graph has {data.num_nodes} nodes and {data.num_edges} edges.\")\n","print(f\"Each node has {data.num_node_features} features.\")\n","print(f\"There are {dataset.num_classes} classes for node classification.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSiaHTndxsJq","executionInfo":{"status":"ok","timestamp":1730769182898,"user_tz":300,"elapsed":6477,"user":{"displayName":"Manish_Kumar Deep_Learning","userId":"10787978629583361420"}},"outputId":"5c4e8413-4a5d-4deb-d015-3a618d32bd23"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n","Processing...\n"]},{"output_type":"stream","name":"stdout","text":["Dataset has 1 graph(s). Each graph has 2708 nodes and 10556 edges.\n","Each node has 1433 features.\n","There are 7 classes for node classification.\n"]},{"output_type":"stream","name":"stderr","text":["Done!\n"]}]},{"cell_type":"code","source":["# Print unique classes and their counts\n","unique_classes, counts = torch.unique(data.y, return_counts=True)\n","\n","class_labels = ['Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory']\n","print(\"Classes and their corresponding node counts:\")\n","for class_label, count in zip(class_labels, counts):\n","    print(f\"{class_label}: {count} nodes\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aqxIgMiGx897","executionInfo":{"status":"ok","timestamp":1730769195202,"user_tz":300,"elapsed":152,"user":{"displayName":"Manish_Kumar Deep_Learning","userId":"10787978629583361420"}},"outputId":"d32c6053-9787-4e9b-df8d-e2f8606e1516"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Classes and their corresponding node counts:\n","Case_Based: 351 nodes\n","Genetic_Algorithms: 217 nodes\n","Neural_Networks: 418 nodes\n","Probabilistic_Methods: 818 nodes\n","Reinforcement_Learning: 426 nodes\n","Rule_Learning: 298 nodes\n","Theory: 180 nodes\n"]}]},{"cell_type":"markdown","source":["Each call to self.conv1(x, edge_index) or self.conv2(x, edge_index) internally performs the linear transformation, aggregation, and normalization described below.\n","Step 1: Linear Transformation\n","Before any messages are passed between nodes, each node's feature vector undergoes a linear transformation using a weight matrix that is learned during training. This transformation is applied to all node features simultaneously, which can be efficiently implemented as a matrix multiplication:\n","X' = XW\n","Where:\n","*   X is is the matrix of input features for all nodes.\n","*   W is the weight matrix associated with the layer.\n","\n","Step 2: Aggregation\n","After the initial transformation, the next step is to aggregate features from the neighboring nodes. In the case of the standard GCNConv, this aggregation is typically a sum (or mean or max) of the features of the neighboring nodes\n","\n","Step 3: Update Function\n","In the standard implementation of GCNConv, after aggregation, the aggregated features are normalized using the degrees of the nodes. This normalization is a crucial step and is done to avoid nodes with high degrees dominating the feature representation.\n","\n","When using GCNConv, much of this complexity is abstracted away, and the layer can be applied directly like any other module in PyTorch.\n","\n"],"metadata":{"id":"ynslcHsA_PL-"}},{"cell_type":"code","source":["class GCN(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels):\n","        super(GCN, self).__init__()\n","        # Define the GCN layers\n","        self.conv1 = GCNConv(in_channels, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, out_channels)\n","\n","    def forward(self, x, edge_index):\n","        # First GCN layer + ReLU activation\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","\n","        # Second GCN layer + log_softmax for classification probabilities\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)"],"metadata":{"id":"ZfQ6fiYf3s1W","executionInfo":{"status":"ok","timestamp":1730769199144,"user_tz":300,"elapsed":169,"user":{"displayName":"Manish_Kumar Deep_Learning","userId":"10787978629583361420"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#Set up the model, optimizer, and device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = GCN(in_channels=dataset.num_node_features, hidden_channels=16, out_channels=dataset.num_classes).to(device)\n","data = data.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"],"metadata":{"id":"ioKwtvuO4O-k","executionInfo":{"status":"ok","timestamp":1730769201320,"user_tz":300,"elapsed":397,"user":{"displayName":"Manish_Kumar Deep_Learning","userId":"10787978629583361420"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def train():\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data.x, data.edge_index)\n","    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])  # Only use training nodes\n","    loss.backward()\n","    optimizer.step()\n","    return loss.item()\n"],"metadata":{"id":"RljeVZhB4kc9","executionInfo":{"status":"ok","timestamp":1730769211197,"user_tz":300,"elapsed":162,"user":{"displayName":"Manish_Kumar Deep_Learning","userId":"10787978629583361420"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def test():\n","    model.eval()\n","    out = model(data.x, data.edge_index)\n","    pred = out.argmax(dim=1)  # Get predicted class\n","    accs = []\n","    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n","        correct = (pred[mask] == data.y[mask]).sum()\n","        acc = int(correct) / int(mask.sum())\n","        accs.append(acc)\n","    return accs  # Returns training, validation, and test accuracy\n"],"metadata":{"id":"6ssdb6Sm4phk","executionInfo":{"status":"ok","timestamp":1730769232050,"user_tz":300,"elapsed":199,"user":{"displayName":"Manish_Kumar Deep_Learning","userId":"10787978629583361420"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["for epoch in range(1, 201):  # Training for 200 epochs\n","    loss = train()\n","    train_acc, val_acc, test_acc = test()\n","    if epoch % 10 == 0:\n","        print(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, \"\n","              f\"Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADUwaTLq4sgu","executionInfo":{"status":"ok","timestamp":1730769247589,"user_tz":300,"elapsed":3078,"user":{"displayName":"Manish_Kumar Deep_Learning","userId":"10787978629583361420"}},"outputId":"f6d2bcbd-0983-4dcb-9d81-dac332b48948"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 010, Loss: 0.6314, Train Acc: 0.9857, Val Acc: 0.7740, Test Acc: 0.7860\n","Epoch: 020, Loss: 0.1008, Train Acc: 1.0000, Val Acc: 0.7700, Test Acc: 0.7870\n","Epoch: 030, Loss: 0.0244, Train Acc: 1.0000, Val Acc: 0.7680, Test Acc: 0.7840\n","Epoch: 040, Loss: 0.0133, Train Acc: 1.0000, Val Acc: 0.7700, Test Acc: 0.7940\n","Epoch: 050, Loss: 0.0124, Train Acc: 1.0000, Val Acc: 0.7700, Test Acc: 0.7970\n","Epoch: 060, Loss: 0.0142, Train Acc: 1.0000, Val Acc: 0.7760, Test Acc: 0.8040\n","Epoch: 070, Loss: 0.0161, Train Acc: 1.0000, Val Acc: 0.7780, Test Acc: 0.8060\n","Epoch: 080, Loss: 0.0168, Train Acc: 1.0000, Val Acc: 0.7780, Test Acc: 0.8070\n","Epoch: 090, Loss: 0.0164, Train Acc: 1.0000, Val Acc: 0.7780, Test Acc: 0.8050\n","Epoch: 100, Loss: 0.0155, Train Acc: 1.0000, Val Acc: 0.7820, Test Acc: 0.8060\n","Epoch: 110, Loss: 0.0145, Train Acc: 1.0000, Val Acc: 0.7800, Test Acc: 0.8030\n","Epoch: 120, Loss: 0.0138, Train Acc: 1.0000, Val Acc: 0.7800, Test Acc: 0.8040\n","Epoch: 130, Loss: 0.0131, Train Acc: 1.0000, Val Acc: 0.7780, Test Acc: 0.8060\n","Epoch: 140, Loss: 0.0125, Train Acc: 1.0000, Val Acc: 0.7800, Test Acc: 0.8080\n","Epoch: 150, Loss: 0.0120, Train Acc: 1.0000, Val Acc: 0.7820, Test Acc: 0.8050\n","Epoch: 160, Loss: 0.0116, Train Acc: 1.0000, Val Acc: 0.7820, Test Acc: 0.8050\n","Epoch: 170, Loss: 0.0111, Train Acc: 1.0000, Val Acc: 0.7820, Test Acc: 0.8060\n","Epoch: 180, Loss: 0.0108, Train Acc: 1.0000, Val Acc: 0.7800, Test Acc: 0.8080\n","Epoch: 190, Loss: 0.0104, Train Acc: 1.0000, Val Acc: 0.7800, Test Acc: 0.8090\n","Epoch: 200, Loss: 0.0101, Train Acc: 1.0000, Val Acc: 0.7800, Test Acc: 0.8080\n"]}]}]}